# sec13f_moat.py
import re
import time
import json
import requests
import xml.etree.ElementTree as ET
from functools import lru_cache

# =========================
# ä½ è‡ªå·±æƒ³è¿½è¸ªçš„æœºæ„ï¼ˆå¯åŠ å¯å‡ï¼‰
# CIK è¦ 10 ä½æ•°ï¼ˆå·¦è¾¹è¡¥ 0ï¼‰
# =========================
CIK_MAP = {
    "BlackRock": "0001364742",
    "Vanguard":  "0000102909",
    "State Street": "0000093751",
    # ä½ æƒ³åŠ å¤šå‡ é—´å¯ä»¥å†åŠ 
}

# ä¸€äº›å¸¸è§ ticker -> cusip çš„å…œåº•ï¼ˆå¯æ…¢æ…¢åŠ ï¼‰
CUSIP_MAP = {
    "AAPL": "037833100",
    "MSFT": "594918104",
    "NVDA": "67066G104",
    "TSLA": "88160R101",
    "AVGO": "11135F101",
    "GOOG": "02079K305",
    "GOOGL": "02079K107",
    "AMZN": "023135106",
    "META": "30303M102",
}

# SEC è¦æ±‚å¸¦ User-Agentï¼ˆå†™ä½ è‡ªå·±èµ„æ–™ï¼Œæœ€å°‘è¦æœ‰ contactï¼‰
SEC_HEADERS = {
    "User-Agent": "stock_bot_app (your_email@example.com)",
    "Accept-Encoding": "gzip, deflate",
    "Host": "data.sec.gov"
}

def _sec_get(url: str, timeout=20):
    # åŸºæœ¬ rate limitï¼Œé¿å… 429
    time.sleep(0.2)
    r = requests.get(url, headers=SEC_HEADERS, timeout=timeout)
    r.raise_for_status()
    return r

def _normalize_cusip(x: str) -> str:
    if not x:
        return ""
    x = x.strip().upper()
    x = re.sub(r"[^0-9A-Z]", "", x)
    return x

def _parse_13f_xml(url: str) -> dict[str, float]:
    """
    è§£æ 13F ä¿¡æ¯è¡¨ XMLï¼Œè¿”å›ï¼šcusip -> shares
    æ³¨æ„ï¼šä¸åŒ 13F XML çš„ namespace å¯èƒ½ä¸åŒï¼Œæ‰€ä»¥è¦å…¼å®¹æ‰¾ tag
    """
    holdings: dict[str, float] = {}
    xml_text = _sec_get(url).text

    root = ET.fromstring(xml_text)

    # å…¼å®¹ namespaceï¼šç›´æ¥ç”¨ endswith å»æŠ“
    def findall_endswith(node, suffix: str):
        out = []
        for el in node.iter():
            if el.tag.endswith(suffix):
                out.append(el)
        return out

    info_tables = [el for el in root.iter() if el.tag.endswith("infoTable")]
    if not info_tables:
        # æœ‰å•²æ–‡ä»¶ infoTable å¯èƒ½åŒ…å¾—æ›´æ·±
        info_tables = findall_endswith(root, "infoTable")

    for t in info_tables:
        cusip_el = None
        shares_el = None

        for el in t.iter():
            if el.tag.endswith("cusip"):
                cusip_el = el
            if el.tag.endswith("sshPrnamt"):  # shares amount
                shares_el = el

        cusip = _normalize_cusip(cusip_el.text if cusip_el is not None else "")
        if not cusip:
            continue

        shares_txt = (shares_el.text if shares_el is not None else "") or ""
        try:
            shares = float(shares_txt.replace(",", "").strip())
        except Exception:
            shares = 0.0

        if shares > 0:
            holdings[cusip] = holdings.get(cusip, 0.0) + shares

    return holdings

def _pick_two_recent_13f_xml_urls(cik10: str) -> list[str]:
    """
    ç”¨ SEC submissions API æ‰¾è¯¥æœºæ„æœ€è¿‘ä¸¤ä»½ 13F-HR çš„ä¿¡æ¯è¡¨ XML
    """
    sub_url = f"https://data.sec.gov/submissions/CIK{cik10}.json"
    sub = _sec_get(sub_url).json()

    filings = sub.get("filings", {}).get("recent", {})
    forms = filings.get("form", []) or []
    acc_nums = filings.get("accessionNumber", []) or []
    prim_docs = filings.get("primaryDocument", []) or []

    picked = []
    for form, acc, prim in zip(forms, acc_nums, prim_docs):
        if form != "13F-HR":
            continue
        # accession å½¢å¦‚ "000xxxx-yy-zzzzzz"
        acc_nodash = acc.replace("-", "")
        base = f"https://www.sec.gov/Archives/edgar/data/{int(cik10)}/{acc_nodash}/"

        # 13F ä¿¡æ¯è¡¨é€šå¸¸å« "infotable.xml" / "informationtable.xml" / "*infotable*.xml"
        # æœ€ç¨³ï¼šç›´æ¥çŒœä¸¤ä¸ªå¸¸è§åï¼Œå¤±è´¥å† fallback ç”¨ index.json æ‰¾
        candidates = [
            base + "infotable.xml",
            base + "informationtable.xml",
            base + "infoTable.xml",
        ]

        ok_url = None
        for u in candidates:
            try:
                _sec_get(u, timeout=12)
                ok_url = u
                break
            except Exception:
                pass

        if not ok_url:
            # fallbackï¼šæ‹‰ index.jsonï¼Œæ‰¾ xml
            try:
                idx = _sec_get(base + "index.json", timeout=12).json()
                items = idx.get("directory", {}).get("item", []) or []
                for it in items:
                    name = (it.get("name") or "").lower()
                    if name.endswith(".xml") and ("info" in name and "table" in name):
                        ok_url = base + it["name"]
                        break
            except Exception:
                ok_url = None

        if ok_url:
            picked.append(ok_url)

        if len(picked) >= 2:
            break

    return picked

@lru_cache(maxsize=256)
def get_institutional_moat_sec13f(ticker: str, top_n: int = 6) -> dict:
    ticker = (ticker or "").upper().strip()

    result = {
        "title": "ğŸ› æœºæ„æŒä»“åŠ¨å‘ (SEC 13F)",
        "summary": "æ­£åœ¨åŒ¹é… SEC 13F æŒä»“ï¼ˆæŒ‰ CUSIPï¼‰â€¦",
        "rows": [],
        "note": "æ•°æ®æ¥è‡ª SEC 13F æŠ¥å‘Šï¼Œå­˜åœ¨å»¶è¿Ÿï¼ˆå­£åº¦æŠ«éœ²ï¼‰",
    }

    # 1) å…ˆæ‹¿ cusipï¼ˆyfinance æœ‰æ—¶ä¼šæ— /æ…¢ï¼Œæ‰€ä»¥åŠ å…œåº•è¡¨ï¼‰
    cusip = None
    try:
        import yfinance as yf
        info = yf.Ticker(ticker).info or {}
        cusip = info.get("cusip")
    except Exception:
        pass

    cusip = _normalize_cusip(cusip or "")
    if not cusip:
        cusip = _normalize_cusip(CUSIP_MAP.get(ticker, ""))

    if not cusip:
        result["summary"] = f"æ‰¾ä¸åˆ° {ticker} çš„ CUSIPï¼Œæš‚æ—¶æ— æ³•åŒ¹é… 13F æ•°æ®"
        return result

    # 2) å¯¹æ¯ä¸ªæœºæ„ï¼šå–æœ€è¿‘ä¸¤ä»½ 13F ä¿¡æ¯è¡¨ï¼Œç®— delta / pct
    rows = []
    hits = 0

    for name, cik10 in CIK_MAP.items():
        try:
            urls = _pick_two_recent_13f_xml_urls(cik10)
            if len(urls) < 2:
                continue

            now_holdings = _parse_13f_xml(urls[0])
            prev_holdings = _parse_13f_xml(urls[1])

            now_sh = float(now_holdings.get(cusip, 0.0))
            prev_sh = float(prev_holdings.get(cusip, 0.0))

            if now_sh == 0 and prev_sh == 0:
                continue

            delta = now_sh - prev_sh
            pct = (delta / prev_sh * 100.0) if prev_sh > 0 else None

            arrow = "â–²" if delta > 0 else ("â–¼" if delta < 0 else "â€”")
            if pct is None:
                value = f"{arrow} æœ¬å­£ {now_sh:,.0f} è‚¡ï¼ˆä¸Šå­£ 0ï¼‰"
            else:
                value = f"{arrow} æœ¬å­£ {now_sh:,.0f} è‚¡ï¼Œå˜åŒ– {delta:,.0f}ï¼ˆ{pct:+.2f}%ï¼‰"

            rows.append({"label": name, "value": value, "_now": now_sh, "_abs_delta": abs(delta)})
            hits += 1
        except Exception:
            continue

    if not rows:
        result["summary"] = "æœªåœ¨è¿½è¸ªçš„æœºæ„åå•ä¸­å‘ç°è¯¥è‚¡æŒä»“è®°å½•ï¼ˆå¯èƒ½æ˜¯åŒ¹é…ä¸åˆ° CUSIP / æˆ–è¯¥æœºæ„æœªæŒæœ‰ï¼‰ã€‚"
        return result

    # âœ… æ’åºåå– top_n
    rows.sort(key=lambda r: r.get("_now", 0), reverse=True)  # æˆ–æ”¹ç”¨ _abs_delta
    rows = rows[:top_n]
    for r in rows:
        r.pop("_now", None)
        r.pop("_abs_delta", None)

    result["rows"] = rows
    result["summary"] = f"å·²æ‰¾åˆ° {hits} å®¶æœºæ„çš„å­£åº¦æŒä»“å˜åŒ–ï¼ˆä»¥ CUSIP åŒ¹é…ï¼‰ã€‚"
    return result